{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1S-WDDXiXIolNcOwtT9QfDkMYLu-7XhmR","timestamp":1694588969698}],"authorship_tag":"ABX9TyPH7yTTKkEqKiOs/w6UwSbm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"e94vds_2sqiI","executionInfo":{"status":"ok","timestamp":1695872878606,"user_tz":-180,"elapsed":3,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}}},"outputs":[],"source":["import gym\n","import numpy as np\n","import time\n","import random\n","from IPython.display import clear_output\n","from time import sleep\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"code","source":["env=gym.make(\"Taxi-v3\", render_mode=\"ansi\") #если ставить render_mode=\"rgb_array\", то обучаться будет вечность\n","env.reset()\n","step = env.render()\n","print(step[0])\n","#plt.imshow(step[0])"],"metadata":{"id":"IEtN96VOyLSy","executionInfo":{"status":"ok","timestamp":1695872901368,"user_tz":-180,"elapsed":527,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8efea075-9351-4a63-ace2-987e725c23ce"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["print(env.action_space)\n","print(env.observation_space)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EfYrbo6zLGD","executionInfo":{"status":"ok","timestamp":1695872908694,"user_tz":-180,"elapsed":590,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"outputId":"dc548fbc-34d4-4cf6-9953-c1cfca0f2f71"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Discrete(6)\n","Discrete(500)\n"]}]},{"cell_type":"code","source":["q_table = np.zeros([env.observation_space.n, env.action_space.n])"],"metadata":{"id":"mYc3O5JmusN3","executionInfo":{"status":"ok","timestamp":1695872911972,"user_tz":-180,"elapsed":534,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["q_table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDlbz2LyoTqB","executionInfo":{"status":"ok","timestamp":1695872913872,"user_tz":-180,"elapsed":3,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"outputId":"e4295fd2-5676-415c-db71-a0ab9e99f4fa"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Training the agent. Этот код для обучения агента, как я понимаю."],"metadata":{"id":"bFTI_5LXJu9e"}},{"cell_type":"code","source":["# Hyperparameters\n","alpha = 0.1\n","gamma = 0.6\n","epsilon = 0.1\n","\n","num_episodes = 10000\n","epochs, reward, wins = 0, 0, 0\n","\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    epochs, reward, wins\n","    done = False\n","\n","    while not done:\n","        if random.uniform(0, 1) < epsilon:\n","            action = env.action_space.sample() # Explore action space\n","        else:\n","            action = np.argmax(q_table[state]) # Exploit learned values\n","\n","        next_state, reward, done,_ = env.step(action)\n","\n","        old_value = q_table[state, action]\n","        next_max = np.max(q_table[next_state])\n","        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n","        q_table[state, action] = new_value\n","        if reward == 20:\n","          wins += 1\n","        state= next_state\n","        epochs += 1"],"metadata":{"id":"_uwJ7_ZApEdf","executionInfo":{"status":"ok","timestamp":1695872954246,"user_tz":-180,"elapsed":36259,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Evaluate agent's"],"metadata":{"id":"uVlq7DPUIgIM"}},{"cell_type":"code","source":["num_episodes = 10000\n","epochs, reward, wins = 0, 0, 0\n","\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    epochs, reward, wins\n","    done = False\n","\n","    while not done:\n","\n","      action = np.argmax(q_table[state])              # Exploit learned values\n","      next_state, reward, done,_ = env.step(action)\n","      if reward == 20:\n","        wins += 1\n","      state= next_state\n","      epochs += 1\n","\n","print(f\"Results after {num_episodes} episodes:\")\n","print(wins)\n","print(f\"Average wins per episode: {wins / num_episodes}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcpMOw3BEKqP","executionInfo":{"status":"ok","timestamp":1695873053301,"user_tz":-180,"elapsed":38116,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"outputId":"f4958219-43cf-4879-b97c-c44153ad3718"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Results after 10000 episodes:\n","8858\n","Average wins per episode: 0.8858\n"]}]},{"cell_type":"markdown","source":["Код для отрисовки выигранного эпизода"],"metadata":{"id":"KbyM48KPigyh"}},{"cell_type":"code","source":["epochs, reward, wins = 0, 0, 0\n","num_episodes = 1\n","frames = []\n","\n","for episode in range(1):\n","\n","    state = env.reset()\n","    epochs, reward, wins\n","    done = False\n","\n","    while not done:\n","\n","      action = np.argmax(q_table[state]) # Exploit learned values\n","      next_state, reward, done,_ = env.step(action)\n","      if reward == 20:\n","        wins += 1\n","      state= next_state\n","      epochs += 1\n","\n","      # Put each rendered frame into dict for animation\n","      frames.append({\n","          'frame': env.render(mode='ansi'),\n","          'episode': num_episodes,\n","          'state': state,\n","          'action': action,\n","          'reward': reward\n","            }\n","        )\n","\n","print(f\"Results after {num_episodes} episodes:\")\n","print(wins)\n","print(f\"Average wins per episode: {wins / num_episodes}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Avk5p1Wm8v6J","executionInfo":{"status":"ok","timestamp":1695873920003,"user_tz":-180,"elapsed":570,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"outputId":"5862ccc0-eeae-4d19-d50a-6ada72999df8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Results after 1 episodes:\n","1\n","Average wins per episode: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["def print_frames(frames):\n","    for i, frame in enumerate(frames):\n","        clear_output(wait=True)\n","        print(frame['frame'][0])\n","        #plt.imshow(frame['frame'])\n","        print(f\"Episode: {frame['episode']}\")\n","        print(f\"Timestep: {i + 1}\")\n","        print(f\"State: {frame['state']}\")\n","        print(f\"Action: {frame['action']}\")\n","        print(f\"Reward: {frame['reward']}\")\n","        time.sleep(1)"],"metadata":{"id":"RxdmYYsJBUYO","executionInfo":{"status":"ok","timestamp":1695873933297,"user_tz":-180,"elapsed":494,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a19c790-97b0-4cbc-c731-5baa6d12163e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["print_frames(frames)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A51Z04o3H-Z-","executionInfo":{"status":"ok","timestamp":1695733900197,"user_tz":-180,"elapsed":9935,"user":{"displayName":"Сергей Жуков","userId":"08674552531602215998"}},"outputId":"25ccf93d-247a-4666-ad26-72842c407576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['+---------+\\n|\\x1b[35m\\x1b[34;1m\\x1b[43mR\\x1b[0m\\x1b[0m\\x1b[0m: | : :G|\\n| : | : : |\\n| : : : : |\\n| | : | : |\\n|Y| : |B: |\\n+---------+\\n  (Dropoff)\\n']\n","Episode: 1\n","Timestep: 10\n","State: 0\n","Action: 5\n","Reward: 20\n"]}]}]}